guid: 47f53122-cc5c-4172-901a-cd3cf6d5085f
name: AzureAiContentSafetyStudio
title: 'Protect against jailbreak attacks: Use Azure AI Content Safety Studio to detect
  jailbreak risks.'
description: Detect jailbreak attempts to identify and block prompts that try to bypass
  the safety mechanisms of your Azure OpenAI deployments.
source:
  type: revcl
  file: ./checklists-ext/wafsg_checklist.en.json
services:
- Azure Openai
resourceTypes:
- Microsoft.CognitiveServices/accounts
waf: Security
labels: {}
links: []
queries: []
reviewed: August 26, 2024
