description: Detect jailbreak attempts to identify and block prompts that try to bypass
  the safety mechanisms of your Azure OpenAI deployments.
guid: 47f53122-cc5c-4172-901a-cd3cf6d5085f
labels: {}
links: []
queries: []
resourceTypes:
- Microsoft.CognitiveServices/accounts
service: OpenAI
source:
  file: ./checklists-ext/wafsg_checklist.en.json
  type: local
title: 'Protect against jailbreak attacks: Use Azure AI Content Safety Studio to detect
  jailbreak risks.'
waf: Security
