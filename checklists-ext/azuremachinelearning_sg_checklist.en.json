{
    "$schema": "https://raw.githubusercontent.com/Azure/review-checklists/main/checklists/checklist.schema.json",
    "items": [
        {
            "waf": "Reliability",
            "service": "Azure Machine Learning",
            "text": "Multi-region model deployment: For enhanced reliability and availability, consider a multi-region deployment environment when possible.",
            "description": "A multi-region deployment ensures that your Machine Learning workloads continue to run even if one region experiences an outage. Multi-region deployment improves load distribution across regions, potentially enhancing performance for users located in different geographical areas. For more information, see Failover for business continuity and disaster recovery.",
            "type": "recommendation"
        },
        {
            "waf": "Reliability",
            "service": "Azure Machine Learning",
            "text": "Model training resiliency: Use checkpointing features supported by Machine Learning including Azure Container for PyTorch, the TensorFlow Estimator class, or the Run object and the FileDataset class that support model checkpointing.",
            "description": "Model checkpointing periodically saves the state of your machine learning model during training, so that it can be restored in case of interruption, failure, or termination. For more information, see Boost checkpoint speed and reduce cost with Nebula.",
            "type": "recommendation"
        },
        {
            "waf": "Reliability",
            "service": "Azure Machine Learning",
            "text": "Use the Dedicated virtual machine tier for compute clusters: Use the Dedicated virtual machine tier for compute clusters for batch inferencing to ensure your batch job isn't preempted.",
            "description": "Low-priority virtual machines come at a reduced price but are preemptible. Clusters that use the Dedicated virtual machine tier aren't preempted.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Security baseline: To enhance the security and compliance of your Machine Learning Service, apply the Azure security baseline for Machine Learning.",
            "description": "The security baseline provides tailored guidance on crucial security aspects such as network security, identity management, data protection, and privileged access. For optimal security, use Microsoft Defender for Cloud to monitor these aspects.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Managed virtual network isolation: Configure managed virtual network isolation for Machine Learning. When you enable managed virtual network isolation, a managed virtual network is created for the workspace. Managed compute resources you create for the workspace automatically use this managed virtual network. If you can't implement managed virtual network isolation, then you must follow the network topology recommendations to separate compute into a dedicated subnet away from the rest of the resources in the solution, including the private endpoints for workspace resources.",
            "description": "Managed virtual network isolation enhances security by isolating your workspace from other networks, reducing the risk of unauthorized access. In a scenario in which a breach occurs in another network within your organization, the isolated network of your Machine Learning workspace remains unaffected, protecting your machine learning workloads.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Machine Learning network isolation: Configure a private endpoint for your Machine Learning workspace and connect to the workspace over that private endpoint.",
            "description": "Machine Learning network isolation enhances security by ensuring that access to your workspace is secure and controlled. With a private endpoint configured for your workspace, you can then limit access to your workspace to only occur over the private IP addresses.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Allow only approved outbound access: Configure the outbound mode on the Machine Learning workspace managed outbound access to `Allow only approved outbound` to minimize the risk of data exfiltration. Configure private endpoints, service tags, or fully qualified domain names (FQDNs) for resources that you need to access.",
            "description": "This configuration minimizes the risk of data exfiltration, improving data security. With this configuration enabled, a malicious actor who gains access to your system can\u2019t send your data to an unapproved external destination.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Virtual network isolation for dependent services: Configure dependent services, such as Storage, Key Vault, and Container Registry with private endpoints and disable public access.",
            "description": "Network isolation bolsters security by restricting access to Azure platform as a service (PaaS) solutions to private IP addresses only.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Managed identity: Use managed identities for authentication between Machine Learning and other services.",
            "description": "Managed identities improve security by eliminating the need to store credentials and manually manage and rotate service principals.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Disable local authentication: Disable local authentication for Machine Learning compute clusters and instances.",
            "description": "Disabling local authentication increases the security of your Machine Learning compute and provides centralized control and management of identities and resource credentials.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Disable the public SSH port: Ensure the public Secure Shell (SSH) port is closed on the Machine Learning compute cluster by setting `remoteLoginPortPublicAccess` to `Disabled`. Apply a similar configuration if you use a different compute.",
            "description": "Disabling SSH access helps prevent unauthorized individuals from gaining access and potentially causing harm to your system and protects you against brute force attacks.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Don't provision public IP addresses for Machine Learning compute: Set enableNodePublicIp to `false` when provisioning Machine Learning compute clusters or compute instances. Apply a similar configuration if you use a different compute.",
            "description": "Refrain from provisioning public IP addresses to enhance security by limiting the potential for unauthorized access to your compute instance or clusters.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Get the latest operating system image: Recreate compute instances to get the latest operating system image.",
            "description": "Using the latest images ensures you're maintaining a consistent, stable, and secure environment, including ensuring you have the latest security patches.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Strict Machine Learning workspace access controls: Use Microsoft Entra ID groups to manage workspace access and adhere to the principle of least privilege for RBAC.",
            "description": "Strict workspace access controls enhance security by ensuring that individuals have only the necessary permissions for their role. A data scientist, for instance, might have access to run experiments but not to modify security settings, minimizing potential security risks.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Restrict model catalog deployments: Restrict model deployments to specific registries.",
            "description": "Restricting the deployments from the model catalog to specific registries ensures you only deploy models to approved registries. This approach helps regulate access to the open-source foundational models.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Encrypt data at rest: Consider using customer-managed keys with Machine Learning.",
            "description": "Encrypting data at rest enhances data security by ensuring that sensitive data is encrypted by using keys directly managed by you. If you have a regulatory requirement to manage your own encryption keys, use this feature to comply with that requirement.",
            "type": "recommendation"
        },
        {
            "waf": "Security",
            "service": "Azure Machine Learning",
            "text": "Minimize the risk of data exfiltration: Implement data exfiltration prevention. For example, create a service endpoint policy to filter egress virtual network traffic and permit data exfiltration only to specific Azure Storage accounts.",
            "description": "Minimize the risk of data exfiltration by limiting inbound and outbound requirements.",
            "type": "recommendation"
        },
        {
            "waf": "Cost",
            "service": "Azure Machine Learning",
            "text": "Optimize compute resources: Optimize your compute resources based on the requirements of your workload. Choose the SKU that best suits your workload:<ul><li>General Purpose \u2013 Balanced CPU to memory ratio, good for all purposes.</li><li>Compute Optimized \u2013 High CPU to memory ratio, good for math-heavy computations.</li><li>Memory Optimized \u2013 High memory to CPU, good for in-memory computations or database applications.</li><li>M Series \u2013 Very large machines that have huge amounts of memory and CPU. </li><li> GPU \u2013 Better for models with a high number of variables that can benefit from higher parallelism and specialized core instructions. Typical applications are deep learning, image or video processing, scientific simulations, data mining, and taking advantage of GPU development frameworks. Test with multiple families and document the results as your baseline. As your model and data evolve, the most adequate compute resource might change. Monitor execution times and reevaluate as needed.",
            "description": "Selecting the right compute is critical as it directly impacts the cost of running your workload. Choosing a GPU or a high-performance SKU without proper usage can lead to wasteful spending, while choosing undersized compute can lead to prohibitively long training times and performance problems.",
            "type": "recommendation"
        },
        {
            "waf": "Cost",
            "service": "Azure Machine Learning",
            "text": "Optimize compute scaling: Configure your compute clusters for autoscaling to ensure you only use what you need.For training clusters, set the minimum number of nodes to 0 and configure the amount of time the node is idle to an appropriate time. For less iterative experimentation, reduce the time to save costs. For more iterative experimentation, use a higher time to prevent paying for scaling up or down after each change.",
            "description": "Configure autoscaling for compute clusters to scale down when their usage is low.  Set the minimum number of nodes to 0 for training clusters to scale down to 0 when not in use.",
            "type": "recommendation"
        },
        {
            "waf": "Cost",
            "service": "Azure Machine Learning",
            "text": "Set training termination policies: Set early termination policies to limit the duration of training runs or terminate them early.",
            "description": "Setting termination policies can help you save costs by stopping nonperforming runs early.",
            "type": "recommendation"
        },
        {
            "waf": "Cost",
            "service": "Azure Machine Learning",
            "text": "Use low-priority virtual machines for batch workloads: Consider using low-priority virtual machines for batch workloads that aren't time-sensitive and in which interruptions are recoverable.",
            "description": "Low-priority virtual machines enable a large amount of compute power to be used for a low cost. They take advantage of surplus capacity in Azure.",
            "type": "recommendation"
        },
        {
            "waf": "Cost",
            "service": "Azure Machine Learning",
            "text": "Enable idle shutdown for compute instances: Enable idle shutdown for compute instances or schedule a start and stop time if usage time is known.",
            "description": "By default, compute instances are available to you, accruing cost. Configuring compute instances to shut down when idle or configuring a schedule for them saves cost when they aren't in use.",
            "type": "recommendation"
        },
        {
            "waf": "Cost",
            "service": "Azure Machine Learning",
            "text": "Parallelize training workloads: Consider parallelizing training workloads. Test running them with the help of the parallel components in Machine Learning.",
            "description": "Parallel workloads can be run on multiple smaller instances, potentially yielding cost savings.",
            "type": "recommendation"
        },
        {
            "waf": "Cost",
            "service": "Azure Machine Learning",
            "text": "Azure Reserved VM Instances: Purchase Azure Reserved VM Instances if you have a good estimate of usage over the next one to three years. Take advantage of reserved capacity options for services when you have good estimates of usage.",
            "description": "Purchase Azure Reserved VM Instances to prepay for virtual machine usage and provide discounts with pay-as-you-go pricing. The discount is automatically applied for virtual machine usage that matches the reservation.",
            "type": "recommendation"
        },
        {
            "waf": "Operations",
            "service": "Azure Machine Learning",
            "text": "Minimize Machine Learning workspace instances: Minimize the number of workspaces, when possible, to reduce maintenance.",
            "description": "Limiting the number of workspaces reduces the maintenance effort and cost of operation. For requirements, such as security, you might need multiple separate workspaces. Minimize the number of workspaces when possible.",
            "type": "recommendation"
        },
        {
            "waf": "Operations",
            "service": "Azure Machine Learning",
            "text": "Take advantage of model catalogs and registries: Take advantage of Machine Learning model catalogs and registries to store, version, and share machine learning assets.Use Machine Learning model catalogs to help you implement A/B testing and deployment of models.",
            "description": "Use Machine Learning model registries to store and version your machine learning models to track changes and maintain lineage with the job and datasets used for training. With Machine Learning model catalogs, your data science teams can discover, evaluate, and fine tune pretrained foundational machine learning models. Storing versioned models in Machine Learning model registries supports deployment strategies such as A/B releases, canary releases, and rollbacks.",
            "type": "recommendation"
        },
        {
            "waf": "Operations",
            "service": "Azure Machine Learning",
            "text": "Monitor model performance: Monitor the performance of your deployed models, and detect data drift on datasets.",
            "description": "Monitoring deployed models ensures your models meet the performance requirements.Monitoring data drift helps you detect changes in the input data that can lead to a decline in your model\u2019s performance. Managing data drift helps you ensure that your model provides accurate results over time.",
            "type": "recommendation"
        },
        {
            "waf": "Operations",
            "service": "Azure Machine Learning",
            "text": "Monitor infrastructure: If your models are deployed to online endpoints, enable Application Insights to monitor online endpoints and deployments.Monitor training infrastructure to ensure you're meeting your baseline requirements.Ensure you're collecting resource logs for Machine Learning.",
            "description": "Monitoring endpoints gives you visibility into metrics such as request latency and requests per minute. You can compare your performance versus your baseline and use this information to make changes to compute resources accordingly. Monitoring metrics such as network bytes can alert you if you're approaching quota limits and prevent throttling.Likewise, monitoring your training environment provides you with the information to make changes to your training environment. Use that information to decide to scale in or out, scale up or down with different performant SKUs, or choose between CPUs or GPUs.",
            "type": "recommendation"
        },
        {
            "waf": "Operations",
            "service": "Azure Machine Learning",
            "text": "Curate model training environments: Use curated environments optimized for Machine Learning, when available.",
            "description": "Curated environments are pre-created environments provided by Machine Learning that speed up deployment time and reduce deployment and training latency. Using curated environments improves training and deployment success rates and avoids unnecessary image builds. Curated environments, such as Azure Container for PyTorch, can also be optimized for training large models on Machine Learning.",
            "type": "recommendation"
        },
        {
            "waf": "Performance",
            "service": "Azure Machine Learning",
            "text": "Select appropriate compute services for model training: Consider Machine Learning compute clusters over compute instances for model training if you require autoscaling.Optimize your compute resources based on the training requirements. First choose between CPUs and GPUs. Default to CPUs, but consider GPUs for workloads such as deep learning, image or video processing, or large amounts of data. Next, choose the image SKU that best suits your workload.Use testing to choose the compute option that optimizes cost against training time when determining your baseline.",
            "description": "Selecting the right compute is critical as it directly impacts the training time. Choosing the right SKU and CPU versus GPU ensures your model training can meet your requirements and performance targets. Choosing a low-performance SKU that's overused can lead to prohibitively long training times and performance problems. Compute clusters provide the ability to improve performance by scaling out workloads that support horizontal scaling. This method provides flexibility for handling workloads with different demands and lets you add or remove machines as needed.",
            "type": "recommendation"
        },
        {
            "waf": "Performance",
            "service": "Azure Machine Learning",
            "text": "Model deployment environment scaling: Use the deployment environment\u2019s autoscale capabilities. For AKS deployment environments, use the cluster autoscaler to scale to meet demand. For online endpoints, automatically scale via integration with the Azure Monitor autoscale feature.",
            "description": "Autoscaling adjusts the number of instances of the deployed model to match demand.",
            "type": "recommendation"
        },
        {
            "waf": "Performance",
            "service": "Azure Machine Learning",
            "text": "Monitor model performance: Monitor the performance of your deployed models.",
            "description": "Tracking the performance of models in production alerts you to potential problems such as data drift, prediction drift, data quality, and feature attribution drift.Monitoring data drift helps you detect changes in the input data that can lead to a decline in your model\u2019s performance. Managing data drift helps you ensure that your model provides accurate results over time.",
            "type": "recommendation"
        },
        {
            "waf": "Performance",
            "service": "Azure Machine Learning",
            "text": "Monitor infrastructure: Monitor online endpoints and integrate with Monitor to track and monitor the appropriate metrics and logs. Enable Application Insights when creating online deployments.Monitor training infrastructure and review resource usage such as memory and CPU or GPU usage when training models to ensure you're meeting your baseline requirements.",
            "description": "Monitoring endpoints gives you visibility into metrics such as request latency and requests per minute. You can compare your performance versus your baseline and use this information to make changes to compute resources accordingly. Monitoring metrics such as network bytes can alert you if you're approaching quota limits and prevent throttling.Likewise, monitoring your training environment provides you with the information to make changes to your training environment. Use that information to decide to scale in or out, scale up or down with different performant SKUs, or choose between CPUs or GPUs.",
            "type": "recommendation"
        }
    ],
    "categories": [],
    "waf": [
        {
            "name": "operations"
        },
        {
            "name": "Reliability"
        },
        {
            "name": "reliability"
        },
        {
            "name": "security"
        },
        {
            "name": "Security"
        },
        {
            "name": "cost"
        },
        {
            "name": "Cost"
        },
        {
            "name": "Operations"
        },
        {
            "name": "performance"
        },
        {
            "name": "Performance"
        }
    ],
    "yesno": [
        {
            "name": "Yes"
        },
        {
            "name": "No"
        }
    ],
    "status": [
        {
            "name": "Not verified",
            "description": "This check has not been looked at yet"
        },
        {
            "name": "Open",
            "description": "There is an action item associated to this check"
        },
        {
            "name": "Fulfilled",
            "description": "This check has been verified, and there are no further action items associated to it"
        },
        {
            "name": "N/A",
            "description": "Not applicable for current design"
        },
        {
            "name": "Not required",
            "description": "Not required"
        }
    ],
    "metadata": {
        "name": "Azure Machine Learning Service Guide",
        "waf": "all",
        "state": "preview",
        "timestamp": "June 30, 2024"
    }
}